# uCore minimal host with rootless Podman + ZFS (raidz2) + Nextcloud stack via Quadlet
# Transpile with: butane --strict --pretty -d . -o ucore.ign thisfile.bu
variant: fcos
version: 1.5.0

passwd:
  users:
    - name: core
      groups: [ wheel ]
      ssh_authorized_keys:
        - {{CORE_USER_SSH_PUB}}
      password_hash: {{CORE_USER_PW_HASH}}
    - name: podman
      groups: [ "systemd-journal" ]
      no_create_home: false
      home_dir: /var/home/podman
      shell: /bin/bash

storage:
  directories:
    # Marker dir used by auto-rebase services (per uCore example flow)
    - path: /etc/ucore-autorebase
      mode: 0755
    # Enable user lingering for core (rootless systemd user services at boot)
    - path: /var/lib/systemd/linger
      mode: 0755

  links:
    # Place public certificate in a place accessible from web
    - path: /srv/pods/caddy/var/www/{{CERT_FILE_PUB}}
      target: srv/pods/caddy/pki/authorities/local/root.crt
      hard: false

  files:
    # Enable linger for 'podman' (user services at boot)
    - path: /var/lib/systemd/linger/podman
      mode: 0644
      contents: { inline: "" }

    # Setting up mail relay agent to use GMail with application password
    - path: /var/home/podman/.config/msmtp/config
      mode: 0600
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          defaults
          auth           on
          tls            on
          tls_trust_file /etc/ssl/certs/ca-bundle.crt
          logfile        /var/home/podman/msmtp.log

          account        gmail
          host           smtp.gmail.com
          port           587
          from           {{ADMIN_EMAIL}}
          user           {{ADMIN_EMAIL}}
          password       {GMAIL_APP_PW}}
          account default : gmail

    # ZFS setup script (creates pool/datasets on first boot after rebase)
    - path: /usr/local/bin/zfs-setup
      mode: 0755
      contents:
        inline: |
          #!/usr/bin/env bash
          set -euxo pipefail
          POOL=data
          MARKER=/etc/zfs/.${POOL}_created

          # Adjust these if your "disk 2–5" aren't /dev/sdb–/dev/sde
          DISKS=(/dev/sdb /dev/sdc /dev/sdd /dev/sde)

          id podman >/dev/null 2>&1 || useradd -m -d /var/home/podman podman || true

          if [[ -e "${MARKER}" ]]; then exit 0; fi

          # Wait for ZFS tools (post-rebase to uCore) and block devices
          /usr/bin/modprobe zfs || true
          for d in "${DISKS[@]}"; do
            /usr/bin/udevadm settle --exit-if-exists="$d" || true
          done

          # Create raidz2 (RAID6-equivalent) pool
          if ! /usr/sbin/zpool list "${POOL}" >/dev/null 2>&1; then
            /usr/sbin/zpool create -f -o ashift=12 \
              "${POOL}" raidz2 "${DISKS[@]}"
          fi

          # Base properties common to most datasets
          COMMON_OPTS="-o compression=lz4 -o atime=off -o xattr=sa -o acltype=posixacl"

          # Create datasets with sensible options
          # Nextcloud app data (webroot + data dir)
          /usr/sbin/zfs create ${COMMON_OPTS} -o mountpoint=/srv/pods/nextcloud         "${POOL}/nextcloud"        || true

          # PostgreSQL data (8K records to match PG page size)
          /usr/sbin/zfs create ${COMMON_OPTS} -o mountpoint=/srv/pods/postgres \
              -o recordsize=8K -o logbias=throughput "${POOL}/postgres"                 || true

          # Redis data (small records)
          /usr/sbin/zfs create ${COMMON_OPTS} -o mountpoint=/srv/pods/redis \
              -o recordsize=4K "${POOL}/redis"                                          || true

          # Caddy config + sites + certs
          /usr/sbin/zfs create ${COMMON_OPTS} -o mountpoint=/srv/pods/caddy            "${POOL}/caddy"             || true
          /usr/sbin/zfs create ${COMMON_OPTS} -o mountpoint=/srv/pods/caddy/www        "${POOL}/caddy/www"         || true
          /usr/sbin/zfs create ${COMMON_OPTS} -o mountpoint=/srv/pods/caddy/certs      "${POOL}/caddy/certs"       || true

          chown -R podman:podman /srv/pods
          mkdir -p /etc/zfs && touch "${MARKER}"

    # Caddyfile served from ZFS dataset (reverse proxy to Nextcloud + static cert download)
    - path: /srv/pods/caddy/Caddyfile
      mode: 0644
      contents:
        inline: |
          # HTTP → HTTPS
          :80 {
            redir https://{host}{uri} 308
          }

          # HTTPS with your private cert/key mounted into /data/certs
          :443 {
            tls internal
            encode zstd gzip

            # Allow downloading the public cert at /caddy/{{CERT_FILE_PUB}}
            handle_path /caddy/* {
              root * /var/www
              file_server browse
            }

            # Reverse proxy to Nextcloud container (apache)
            @wellknown path /.well-known/*

            handle @wellknown {
              # Nextcloud well-known redirects per docs
              rewrite /.well-known/carddav /remote.php/dav
              rewrite /.well-known/caldav /remote.php/dav
              reverse_proxy nextcloud:80
            }

            handle {
              header {
                Strict-Transport-Security "max-age=31536000; includeSubDomains; preload"
                X-Content-Type-Options "nosniff"
                X-Frame-Options "SAMEORIGIN"
                Referrer-Policy "no-referrer"
              }
              reverse_proxy nextcloud:80
            }
          }


    # Nextcloud environment
    - path: /var/home/podman/.config/containers/nextcloud.env
      mode: 0600
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          POSTGRES_DB=nextcloud
          POSTGRES_USER=nextcloud
          POSTGRES_PASSWORD={{POSTGRESQL_PW}}
          NEXTCLOUD_ADMIN_USER=admin
          NEXTCLOUD_ADMIN_PASSWORD={{NEXTCLOUD_ADMIN_PW}}
          REDIS_HOST=redis
          REDIS_HOST_PASSWORD={{REDIS_PW}}
          NEXTCLOUD_TRUSTED_DOMAINS={{NEXTCLOUD_TRUSTED_DOMAIN}}

    # Postgres environment
    - path: /var/home/podman/.config/containers/postgres.env
      mode: 0600
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          POSTGRES_DB=nextcloud
          POSTGRES_USER=nextcloud
          POSTGRES_PASSWORD={{POSTGRESQL_PW}}

    # Redis environment
    - path: /var/home/podman/.config/containers/redis.env
      mode: 0600
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          REDIS_PASSWORD={{REDIS_PW}}

    # Shared network for all rootless quadlets
    - path: /var/home/podman/.config/containers/systemd/nextcloud.network
      mode: 0644
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          [Unit]
          Description=User network for Nextcloud stack

          [Network]
          Name=nextcloudnet
          Driver=bridge

    # PostgreSQL quadlet: Store NextCloud meta-data
    - path: /var/home/podman/.config/containers/systemd/postgres.container
      mode: 0644
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          [Unit]
          Description=PostgreSQL for Nextcloud (rootless)
          After=nextcloud.network
          Requires=nextcloud.network
          OnFailure=mail-notify@%n.service

          [Container]
          Image=postgres:16
          Name=postgres
          Network=nextcloudnet
          EnvironmentFile=%h/.config/containers/postgres.env
          # Persist to ZFS dataset
          Volume=/srv/pods/postgres:/var/lib/postgresql/data:Z
          # Healthcheck
          HealthCmd=CMD-SHELL pg_isready -U $$POSTGRES_USER || exit 1
          HealthInterval=30s
          HealthRetries=5
          HealthStartPeriod=40s

          [Service]
          Restart=always

          [Install]
          WantedBy=default.target

    # Redis quadlet: Used by NextCloud
    - path: /var/home/podman/.config/containers/systemd/redis.container
      mode: 0644
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          [Unit]
          Description=Redis for Nextcloud (rootless, with auth)
          After=nextcloud.network
          Requires=nextcloud.network
          OnFailure=mail-notify@%n.service

          [Container]
          Image=redis:7
          Name=redis
          Network=nextcloudnet
          EnvironmentFile=%h/.config/containers/redis.env
          Volume=/srv/pods/redis:/data:Z
          Arg=--appendonly yes
          Arg=--requirepass $${REDIS_PASSWORD}

          [Service]
          Restart=always

          [Install]
          WantedBy=default.target

    # NextCloud quadlet: Offers your own cloud services
    - path: /var/home/podman/.config/containers/systemd/nextcloud.container
      mode: 0644
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          [Unit]
          Description=Nextcloud (rootless)
          After=postgres.service redis.service nextcloud.network
          Requires=postgres.service redis.service nextcloud.network
          OnFailure=mail-notify@%n.service

          [Container]
          Image=nextcloud:29-apache
          Name=nextcloud
          Network=nextcloudnet
          EnvironmentFile=%h/.config/containers/nextcloud.env
          # Persist Nextcloud data to ZFS
          Volume=/srv/pods/nextcloud:/var/www/html:Z

          # Let Nextcloud know the proxied protocol
          Env=APACHE_DISABLE_REWRITE_IP=1

          [Service]
          Restart=always

          [Install]
          WantedBy=default.target

    # Caddy quadlet: Web reverse proxy
    - path: /var/home/podman/.config/containers/systemd/caddy.container
      mode: 0644
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          [Unit]
          Description=Caddy reverse proxy (rootless, private cert)
          After=nextcloud.service nextcloud.network
          Requires=nextcloud.network
          OnFailure=mail-notify@%n.service

          [Container]
          Image=caddy:2
          Name=caddy
          Network=nextcloudnet
          # Map ports 80/443 (rootlesskit handles privileged ports)
          PublishPort=80:80
          PublishPort=443:443
          Volume=/srv/pods/caddy/Caddyfile:/etc/caddy/Caddyfile:Z
          Volume=/srv/pods/caddy/www:/var/www:Z
          Volume=/srv/pods/caddy/certs:/data/certs:Z

          [Service]
          Restart=always

          [Install]
          WantedBy=default.target

    # Systemd USER timer to run weekly PostgreSQL amcheck
    - path: /var/home/podman/.config/systemd/user/pg-amcheck.service
      mode: 0644
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          [Unit]
          Description=Weekly PostgreSQL amcheck (online checks)
          OnFailure=mail-notify@%n.service

          [Service]
          Type=oneshot
          # Run pg_amcheck inside the postgres container
          ExecStart=/usr/bin/podman exec -u postgres postgres pg_amcheck -S -j 2 -d nextcloud

    - path: /var/home/podman/.config/systemd/user/pg-amcheck.timer
      mode: 0644
      user: { name: podman }
      group: { name: podman }
      contents:
        inline: |
          [Unit]
          Description=Run pg_amcheck weekly

          [Timer]
          OnCalendar=weekly
          Persistent=true

          [Install]
          WantedBy=timers.target

systemd:

  #
  # Privileged system wide containers
  #

  units:

    #
    # SystemD services handling setup of the system,
    # These services only run once.
    #

    # Run on first boot, rebases from CoreOS to unsigned uCore distro
    - name: ucore-unsigned-autorebase.service
      enabled: true
      contents: |
        [Unit]
        Description=uCore autorebase to unsigned OCI and reboot
        ConditionPathExists=!/etc/ucore-autorebase/unverified
        ConditionPathExists=!/etc/ucore-autorebase/signed
        After=network-online.target
        Wants=network-online.target

        [Service]
        Type=oneshot
        StandardOutput=journal+console
        ExecStart=/usr/bin/rpm-ostree rebase --bypass-driver ostree-unverified-registry:ghcr.io/ublue-os/ucore-minimal:stable
        ExecStart=/usr/bin/touch /etc/ucore-autorebase/unverified
        ExecStart=/usr/bin/systemctl disable ucore-unsigned-autorebase.service
        ExecStart=/usr/bin/systemctl reboot

        [Install]
        WantedBy=multi-user.target

    # Run on second boot, rebase from unsigned uCore to signed uCore distro
    - name: ucore-signed-autorebase.service
      enabled: true
      contents: |
        [Unit]
        Description=uCore autorebase to signed OCI and reboot
        ConditionPathExists=/etc/ucore-autorebase/unverified
        ConditionPathExists=!/etc/ucore-autorebase/signed
        After=network-online.target
        Wants=network-online.target

        [Service]
        Type=oneshot
        StandardOutput=journal+console
        ExecStart=/usr/bin/rpm-ostree rebase --bypass-driver ostree-image-signed:docker://ghcr.io/ublue-os/ucore-minimal:stable
        ExecStart=/usr/bin/touch /etc/ucore-autorebase/signed
        ExecStart=/usr/bin/systemctl disable ucore-signed-autorebase.service
        ExecStart=/usr/bin/systemctl reboot

        [Install]
        WantedBy=multi-user.target

    # Run on third boot, enable firewall services, ZFS pool/datasets, start containers, timers
    - name: post-setup.service
      enabled: true
      contents: |
        [Unit]
        Description=Post-rebase setup (firewall, ZFS, Quadlet, timers, boot mail)
        ConditionPathExists=/etc/ucore-autorebase/unverified
        ConditionPathExists=/etc/ucore-autorebase/signed
        ConditionPathExists=!/etc/ucore-autorebase/setup
        After=network-online.target
        Wants=network-online.target

        [Service]
        Type=oneshot
        StandardOutput=journal+console

        # Make sure rootless quadlets starts without requiring podman to login
        ExecStart=/usr/bin/loginctl enable-linger podman

        ExecStart=/usr/bin/firewall-cmd --permanent --add-service=http --add-service=https
        ExecStart=/usr/bin/firewall-cmd --reload

        # Create ZFS pool + datasets if not present
        ExecStart=/usr/local/bin/zfs-setup

        # make cert downloadable
        ExecStart=/usr/bin/install -m 0644 -o podman -g podman /srv/pods/caddy/certs/{{CERT_FILE_PUB}} /srv/pods/caddy/www/{{CERT_FILE_PUB}}

        # start podman user's units
        ExecStart=/usr/bin/runuser -l podman -c 'systemctl --user daemon-reload'
        ExecStart=/usr/bin/runuser -l podman -c 'systemctl --user enable --now nextcloud.network'
        ExecStart=/usr/bin/runuser -l podman -c 'systemctl --user enable --now postgres.service redis.service nextcloud.service caddy.service'
        ExecStart=/usr/bin/runuser -l podman -c 'systemctl --user enable --now pg-amcheck.timer

        # enable user timers (failure notify is implicit via OnFailure on each)
        ExecStart=/usr/bin/runuser -l podman -c 'systemctl --user daemon-reload'

        # enable weekly ZFS scrub + Postgres validation timers
        ExecStart=/usr/bin/systemctl enable --now zfs-scrub@data.timer

        ExecStart=/usr/bin/touch /etc/ucore-autorebase/setup
        ExecStart=/usr/bin/systemctl disable post-setup.service

        [Install]
        WantedBy=multi-user.target

    #
    # SystemD services run once setup is completed.
    #

    # Service: Run a ZFS scrub, triggered by zfs-scrub.timer
    - name: zfs-scrub.service
      contents: |
        [Unit]
        Description=ZFS scrub of storage pool
        Wants=zfs.target
        After=zfs.target
        OnFailure=mail-notify@%n.service

        [Service]
        Type=oneshot
        ExecStart=/usr/sbin/zpool scrub tank

    # Timer: Run weekly (Sunday 02:00)
    - name: zfs-scrub.timer
      enabled: true
      contents: |
        [Unit]
        Description=Weekly ZFS scrub

        [Timer]
        OnCalendar=Sun *-*-* 02:00:00
        Persistent=true

        [Install]
        WantedBy=timers.target

    # Send e-mail notification at each reboot
    # This is both to indicate that e-mail notifications work, as well as informing about reboots
    - name: boot-mail.service
      enabled: true
      contents: |
        [Unit]
        Description=Send boot notification email
        After=network-online.target
        Wants=network-online.target

        [Service]
        Type=oneshot
        ExecStart=/bin/sh -c "echo -e 'Subject: [NextCloud server] System $(hostname) booted at $(date)' | msmtp -t {{ADMIN_EMAIL}}"

        [Install]
        WantedBy=multi-user.target

    # Template for failure notifications
    # To use this template, add the following line to systemd service in unit section:
    #   OnFailure=mail-notify@%n.service
    - name: mail-notify@.service
      contents: |
        [Unit]
        Description=Send failure notification email for %i
        After=network-online.target
        Wants=network-online.target

        [Service]
        Type=oneshot
        ExecStart=/bin/sh -c "echo -e 'Subject: [NextCloud server] Service %i failed on $(hostname) at $(date)' | msmtp -t {{ADMIN_EMAIL}}"

