Welcome to NextCloud server repository!

This repository implements needed scripts for spinning up a new NextCloud server. The goal is to
be able to deploy a new NextCloud instance without a lot of hassle.

For a Talos Linux and Helm-based deployment, see the resources under `talos/` and `charts/`.

The process is as follows:

1. Install needed packages used in the ISO image build, see section "Preparation" below.
2. Perform the actual build, see section "Build" below.
3. Write the image to an USB stick, and boot the server with it, see section "Deploy".

The last part of this document describes how it is all designed.

Prerequisites
=============

- Good knowledge about booting Linux live image and using command shell including dmesg command.
  Or knows how to ask an AI for help about this.
- Have a DHCP you know how to configure
- USB memory stick to store a boot image on
- Server to install on with at least 5 discs

Preparations
============

Make sure you have assigned a static IP for your machine. This most likely means you need to know the MAC address,
which sometimes can be seen on the motherboard. Otherwise, boot up a live Linux distro image, go to the command
shell, and use `ip link` to determine the MAC address. Use this MAC address to tell your DHCP server that this
MAC address should be assigned a static IP address. This static address is referred to as `CONTROL_PLANE_IP` below.

Also check with `dmesg` the name of your disc devices. One of them need to be specified as `BOOTDISC`, which is
the disc the server will boot from and will also contain the root file system. The rest (at least 4) will be
specified as `DATADISCS`.

Talm
----

Install Talm to your `~/bin` directory:

    mkdir -p ~/bin
    cd ~/bin
    curl --silent --show-error --location https://github.com/cozystack/talm/releases/latest/download/talm-linux-amd64.tar.gz | tar xz talm

Make sure `PATH` environment variable includes `~/bin`.

Packages - Fedora
-----------------

    dnf install helm

Build
=====

Create a separate build directory. The directory where this file resides in is denoted REPODIR below.

    make -f REPODIR/Makefile OPTIONS

Where OPTIONS is a space separated list of KEY=VALUE. The following options are needed for the build:

ADMIN_EMAIL

Deploy
======

dd yadayada

Testing
=======

To verify the image in a virtual environment, run:

    make test

This builds the ISO image, boots it inside QEMU with five virtual disks and
forwards host port 8080 to the guest's HTTPS port. The script waits for the
installation to complete and then probes `https://localhost:8080/status.php`
to ensure Nextcloud responds.

Design
======


The design goals were:

- Server runs containers, which implements all needed services
- Git repository plus some user configuration should be all needed to deploy a new server
- Easy to perform safe upgrades, preferably in an automated way

Services to be implemented are:
- NextCloud - For most of the user provided services
- PostgreSQL - Database, used by NextCloud
- Redis - In memory database for cache purpose, used by NextCloud
- Caddy - Web proxy/server, used as front-end to NextCloud to provide HTTPS access
- Keycloak - For single sign-on support
- Msmtp - Simple mail transfer agent to send mail notifications

Components used to implement the infrastructure:
- Talos - Linux distribution centered around containers
- Talm - Bootstrap Talos on a new machine, uses Helm
- Helm - Templated Kubernetes container deployment
- Kubernetes - Container deployment and maintenance tool
- OpenEBS - Persistent storage backend for Kubernetes
- Alert Manager - Plugin to OpenEBS to create alerts for Prometheus
- FluxCD - Keep containers up to date using git repository as reference
- Kustomize - Application configuration management, built into kubectl
- RBAC - Extension of Kubernetes to handle permissions, used for FluxCD permissions
- Prometheus - Collect and aggregate metrics about the containers
- Etcd - Configuration storage
- ZFS - Filesystem for implementing persistent storage. Uses encryption with a key shared for all datasets. Supports snapshot, and user data bit corrections.
- K8up - Scheduled backup persistent volume data to manually rotated USB disks

- Using rootless Podman containers, implemented as quadlets
- First disk used as root file system, with default setup
- Disk 2 to 5 becomes RAID6 configuration with ZFS, where ZFS volumes are used for storing persistent data for the containers. Here setup what volumes make sense for the containers including volume options.
- Having the following services:
  - NextCloud
  - PostgreSQL - to be used by NextCloud
  - Redis - for NextCloud
  - Caddy - as web server for NextCloud, configured for using private SSL certificate for HTTPS access
- Caddy's SSL certificate should be downloadable from web server
- Each week ZFS should be scrubbed and PostgreSQL database validated
- Use the uCore recommended way for performing a rebase from CoreOS to uCore.
- A simple mail agent used to send a notification for each bootup as well as when a systemd service fails
- Use password for using Redis and PostgreSQL
- Server user account for admin is core
- Server user account used for running containers is podman
- Root device is auto-crypted using TPM hardware
- ZFS datasets are crypted using key file in root filesystem, also available from the build for recovery purpose.


Talos
=====

Investigate:

Logging
- ELK
- Loki
- Logstash

Visualization:
- Kubernetes Dashboard
- Grafana dashboard

Single sign-on
- Keycloak

Web proxy
- Caddy

Cache
- Redis

Cloud services
- NextCloud

OpenEBS
-------

Provides persistent storage for containers.
Is implemented by itself as container(s). Implements the Kubernetes Container Storage Interface (CSI).

Containers does a Persistent Volume Claims (PVC). A persistent volume claim specify what storage class it needs, and properties of the volume such as size and access (read, write). OpenEBS translates the persistent volume claim  to Persistent Volumes (PV). By default a storage class will only allow one container to access a specific persistent volume. This default can be overridden in the storage class by specifying `shared: "yes` under parameters.

Note that OpenEBS builds on top of existing storage infrastructure, i.e. does not do partitioning of disks.

    helm repo add openebs https://openebs.github.io/openebs
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm repo add nextcloud https://nextcloud.github.io/helm/
    helm repo update
    helm install openebs --namespace openebs openebs/openebs --set engines.replicated.mayastor.enabled=false --create-namespace --set zfs-localpv.zfsNode.kubeletDir=<your-directory-path>
    kubectl create ns monitoring
    helm install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring -f prometheus-settings.yaml
    helm install my-release nextcloud/nextcloud
